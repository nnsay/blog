---
title: ä½¿ç”¨ LlamaIndex æ„å»º RAG åº”ç”¨
date: 2025-09-15 11:08:35
tags:
- DevOps
- AI
  excerpt: å¦‚ä½•ä½¿ç”¨ LlamaIndex æ¡†æ¶ï¼Œç»“åˆé˜¿é‡Œäº‘ç™¾ç‚¼æ¨¡å‹æœåŠ¡ï¼Œä»é›¶å¼€å§‹æ„å»ºä¸€ä¸ªå®Œæ•´çš„ RAG åº”ç”¨çš„å®è·µæŒ‡å—ã€‚
---

# å£°æ˜

æœ¬æ–‡ç”± ğŸ¤–AI æ”¹å†™æ¶¦è‰²è€Œæˆ

# 1. LlamaIndex ç®€ä»‹

[LlamaIndex](https://docs.llamaindex.ai/en/stable/) æ˜¯ä¸€ä¸ªé¢å‘å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åº”ç”¨å¼€å‘çš„å¼ºå¤§æ¡†æ¶ï¼Œä¸“æ³¨äº Agent å’Œå¤æ‚å·¥ä½œæµçš„æ„å»ºï¼Œå°¤å…¶æ“…é•¿äºå¼€å‘æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰åº”ç”¨ã€‚

é€‰æ‹© LlamaIndex çš„ä¸»è¦åŸå› å¦‚ä¸‹ï¼š

- **æ–‡æ¡£ä¸°å¯Œ**ï¼šå®˜æ–¹æ–‡æ¡£åˆ†ç±»æ¸…æ™°ï¼Œæä¾›äº†å¤§é‡ Jupyter Notebook ç¤ºä¾‹ï¼Œå‡ ä¹è¦†ç›–æ‰€æœ‰æ ¸å¿ƒæ¨¡å—ï¼Œæå¤§åœ°é™ä½äº†å­¦ä¹ é—¨æ§›ã€‚
- **ç”Ÿæ€æ”¯æŒå¹¿æ³›**ï¼šLlamaIndex å¯¹æ¥äº†ä¼—å¤šç”Ÿæ€æœåŠ¡ï¼Œä¾‹å¦‚å¯¹å›½å†…é˜¿é‡Œäº‘ç™¾ç‚¼ï¼ˆDashScopeï¼‰çš„æ”¯æŒéå¸¸å……åˆ†ï¼Œæ— è®ºæ˜¯ LLMã€Embedding è¿˜æ˜¯ Rerank æ¨¡å‹æœåŠ¡ï¼Œéƒ½èƒ½è½»æ¾é›†æˆã€‚

æœ¬æ–‡å°†é€šè¿‡ä¸€ä¸ªå®Œæ•´çš„ä»£ç å®è·µï¼Œå±•ç¤ºå¦‚ä½•ä½¿ç”¨ LlamaIndex æ„å»ºä¸€ä¸ªç®€å•çš„ RAG åº”ç”¨ã€‚

# 2. ä»£ç å®è·µ

æœ¬èŠ‚æ‰€æœ‰ä»£ç å‡æºè‡ª Jupyter Notebook é¡¹ç›®ï¼Œæ‚¨å¯ä»¥ç›´æ¥å¤åˆ¶å¹¶æŒ‰é¡ºåºåœ¨è‡ªå·±çš„ç¯å¢ƒä¸­æ‰§è¡Œã€‚

## 2.1 å®‰è£…ä¾èµ–

é¦–å…ˆï¼Œåœ¨æ‚¨çš„ `pyproject.toml` æ–‡ä»¶ä¸­æ·»åŠ ä»¥ä¸‹ä¾èµ–ï¼Œå¹¶ä½¿ç”¨ `uv` æˆ– `poetry` è¿›è¡Œå®‰è£…ã€‚

```toml
"llama-index-core>=0.12.49",
"llama-index-embeddings-dashscope>=0.3.0",
"llama-index-llms-dashscope>=0.3.1",
"llama-index-node-parser-topic>=0.2.0",
"llama-index-readers-json>=0.3.0",
"llama-index-vector-stores-postgres>=0.5.4",
```

## 2.2 å…¨å±€é…ç½®

LlamaIndex çš„å…¨å±€é…ç½®æ˜¯ä¸€å¤§äº®ç‚¹ã€‚é€šè¿‡ä¸€æ¬¡æ€§è®¾ç½®ï¼Œå³å¯åœ¨é¡¹ç›®å„å¤„ç›´æ¥è°ƒç”¨æ¨¡å‹æœåŠ¡ï¼Œæ— éœ€é‡å¤é…ç½®ã€‚è¿™ä½¿å¾—åˆ‡æ¢æ¨¡å‹æˆ–æœåŠ¡æ—¶ï¼Œä»…éœ€ä¿®æ”¹å…¨å±€é…ç½®ï¼Œè€Œæ— éœ€æ”¹åŠ¨ä¸šåŠ¡ä»£ç ã€‚

### 2.2.1 é…ç½®ç¯å¢ƒå˜é‡

åˆ›å»ºä¸€ä¸ª `.env` æ–‡ä»¶æ¥ç®¡ç†æ•æ„Ÿä¿¡æ¯ï¼Œä¸»è¦åŒ…æ‹¬é˜¿é‡Œäº‘ç™¾ç‚¼çš„ API Key å’Œç”¨äºå‘é‡å­˜å‚¨çš„ PostgreSQL æ•°æ®åº“åœ°å€ã€‚

```
DASHSCOPE_API_KEY=sk-xxx
DATABASE_URL=postgresql://root:1qaz2wsx@192.168.110.241:5432/vector_db?schema=public
```

ä½¿ç”¨ `dotenv` åº“åŠ è½½ç¯å¢ƒå˜é‡ï¼š

```python
import os
from dotenv import load_dotenv

load_dotenv(override=True)
```

### 2.2.2 é…ç½® LlamaIndex å…¨å±€è®¾ç½®

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä¸»è¦é…ç½®å…¨å±€çš„ LLM å’Œ Embedding æ¨¡å‹ã€‚

```python
import os
from llama_index.llms.dashscope import DashScope
from llama_index.embeddings.dashscope import (
    DashScopeEmbedding,
    DashScopeTextEmbeddingType,
)
from llama_index.core import Settings

# é…ç½® DashScope LLMï¼Œä¾‹å¦‚ qwen-max-latest
# æ¨¡å‹               æœ€å¤§è¾“å…¥   æœ€å¤§è¾“å‡º
# qwen-max-latest    129,024    8,192
# qwen2.5-14b-instruct 129,024    8,192
dashscope_llm = DashScope(
    model_name="qwen-max-latest",
    api_key=os.environ["DASHSCOPE_API_KEY"],
    max_tokens=8000,
)

# é…ç½® DashScope Embedding æ¨¡å‹
embedder = DashScopeEmbedding(
    model_name="text-embedding-v4",
    text_type=DashScopeTextEmbeddingType.TEXT_TYPE_DOCUMENT,
    api_key=os.environ["DASHSCOPE_API_KEY"],
    embed_batch_size=10,
)

# åº”ç”¨å…¨å±€è®¾ç½®
Settings.embed_model = embedder
Settings.llm = dashscope_llm
Settings.context_window = 131072  # LLM çš„æœ€å¤§è¾“å…¥çª—å£
Settings.num_output = 8192         # ä¸ºæ–‡æœ¬ç”Ÿæˆä¿ç•™çš„ Token æ•°é‡
Settings.chunk_overlap = 50        # æ–‡æœ¬å—é‡å å¤§å°
Settings.chunk_size = 1024         # æ–‡æœ¬å—å¤§å°
```

# 3. åŠ è½½æ–‡æ¡£

LlamaIndex æ”¯æŒä»å¤šç§æ•°æ®æºåŠ è½½æ–‡æ¡£ã€‚æœ¬æ–‡å°†æ¼”ç¤ºä¸¤ç§å¸¸è§æ–¹å¼ï¼šä» JSONL æ–‡ä»¶å’Œæœ¬åœ°æ–‡ä»¶ç³»ç»ŸåŠ è½½ã€‚

## 3.1 ä» JSONL æ–‡ä»¶åŠ è½½

```python
from llama_index.readers.json import JSONReader

reader = JSONReader()
documents = reader.load_data(
    input_file="knowledge/solarsketch/knowledge.jsonl", extra_info={}
)
```

## 3.2 ä»æœ¬åœ°æ–‡ä»¶åŠ è½½

```python
from llama_index.core import SimpleDirectoryReader

reader = SimpleDirectoryReader(
    input_files=["knowledge/books/å¤ªé˜³èƒ½åˆ¶é€  å…‰ä¼ç»„ä»¶çš„ç¯å¢ƒè®¾è®¡æ¦‚å¿µ.md"]
)
documents = reader.load_data(show_progress=True)
```

# 4. æ‹†åˆ†æ–‡æ¡£ (Node Parsing)

åœ¨ LlamaIndex ä¸­ï¼Œ`Node` æ˜¯å¤„ç†æ–‡æ¡£çš„åŸºæœ¬å•å…ƒï¼Œå®ƒä»£è¡¨äº†åŸå§‹æ–‡æ¡£çš„ä¸€ä¸ªç‰‡æ®µã€‚å‘é‡æ•°æ®åº“ä¸­å­˜å‚¨å’Œæ£€ç´¢çš„æ­£æ˜¯è¿™äº› `Node`ã€‚ç§‘å­¦åˆç†çš„æ–‡æ¡£æ‹†åˆ†ç­–ç•¥å¯¹ RAG çš„æ€§èƒ½å’Œæ•ˆæœè‡³å…³é‡è¦ã€‚

## 4.1 ç®€å•æ‹†åˆ† (Simple Spitting)

è¿™æ˜¯ LlamaIndex çš„é»˜è®¤æ‹†åˆ†æ–¹å¼ï¼Œåº•å±‚ä¾èµ– `nltk` åº“è¿›è¡Œè¯­å¥æ‹†åˆ†ã€‚

```python
from llama_index.core.node_parser import SimpleNodeParser

semantic_node_parser = SimpleNodeParser()
nodes = semantic_node_parser.get_nodes_from_documents(documents, show_progress=True)
```

## 4.2 è¯­ä¹‰æ‹†åˆ† (Semantic Splitting)

è¯­ä¹‰æ‹†åˆ†æ˜¯æˆ‘ä¸ªäººæ¨èçš„æ–¹å¼ï¼Œå…¼å…·æ•ˆç‡ä¸æ•ˆæœã€‚å®ƒé¦–å…ˆæŒ‰å¥å­æ‹†åˆ†ï¼Œç„¶åé€šè¿‡è®¡ç®—è¯­ä¹‰ç›¸å…³æ€§å°†å…³è”ç´§å¯†çš„å¥å­åˆå¹¶æˆä¸€ä¸ªè¯­ä¹‰å—ã€‚

```python
from llama_index.core.node_parser import (
    SemanticSplitterNodeParser,
)

semantic_node_parser = SemanticSplitterNodeParser(embed_model=Settings.embed_model)
nodes = semantic_node_parser.get_nodes_from_documents(documents, show_progress=True)
```

## 4.3 è¯é¢˜æ‹†åˆ† (Topic Splitting)

è¿™æ˜¯ä¸€ç§ä¾èµ– LLM è¿›è¡Œæ‹†åˆ†çš„é«˜çº§æ–¹å¼ã€‚å®ƒé€šè¿‡ç‰¹å®šçš„ Prompt æŒ‡å¯¼å¤§æ¨¡å‹å°†æ–‡æ¡£å†…å®¹åˆ†è§£ä¸ºä¸€ç³»åˆ—ç‹¬ç«‹çš„å‘½é¢˜ã€‚ä»¥ä¸‹æ˜¯å…¶é»˜è®¤çš„ç³»ç»Ÿ Promptï¼š

```
PROPOSITION_SYSTEM_PROMPT = """Decompose the given content into clear and simple propositions, ensuring they are interpretable out of context. Follow these rules:
1. Split compound sentences into simple sentences. Maintain the original phrasing from the input whenever possible.
2. For any named entity that is accompanied by additional descriptive information, separate this information into its own distinct proposition.
3. Decontextualize the proposition by adding necessary modifiers to nouns or entire sentences and replacing pronouns (e.g., 'it', 'he', 'she', 'they', 'this', 'that') with the full name of the entities they refer to.
4. Present the results as a list of strings, formatted in JSON.
Here's an example:
Input: Title: Ã‰ostre. Section: Theories and interpretations, Connection to Easter Hares. Content:
The earliest evidence for the Easter Hare (Osterhase) was recorded in south-west Germany in 1678 by the professor of medicine Georg Franck von Franckenau, but it remained unknown in other parts of Germany until the 18th century. Scholar Richard Sermon writes that "hares were frequently seen in gardens in spring, and thus may have served as a convenient explanation for the origin of the colored eggs hidden there for children. Alternatively, there is a European tradition that hares laid eggs, since a hare's scratch or form and a lapwing's nest look very similar, and both occur on grassland and are first seen in the spring. In the nineteenth century the influence of Easter cards, toys, and books was to make the Easter Hare/Rabbit popular throughout Europe. German immigrants then exported the custom to Britain and America where it evolved into the Easter Bunny."
Output: [ "The earliest evidence for the Easter Hare was recorded in south-west Germany in 1678 by Georg Franck von Franckenau.", "Georg Franck von Franckenau was a professor of medicine.", "The evidence for the Easter Hare remained unknown in other parts of Germany until the 18th century.", "Richard Sermon was a scholar.", "Richard Sermon writes a hypothesis about the possible explanation for the connection between hares and the tradition during Easter", "Hares were frequently seen in gardens in spring.", "Hares may have served as a convenient explanation for the origin of the colored eggs hidden in gardens for children.", "There is a European tradition that hares laid eggs.", "A hare's scratch or form and a lapwing's nest look very similar.", "Both hares and lapwing's nests occur on grassland and are first seen in the spring.", "In the nineteenth century the influence of Easter cards, toys, and books was to make the Easter Hare/Rabbit popular throughout Europe.", "German immigrants exported the custom of the Easter Hare/Rabbit to Britain and America.", "The custom of the Easter Hare/Rabbit evolved into the Easter Bunny in Britain and America." ]"""
```

è™½ç„¶ç†è®ºä¸Šè¿™ç§æ–¹å¼çš„æ£€ç´¢æ•ˆæœæ›´å¥½ï¼Œä½†å®ƒä¾èµ– LLM è°ƒç”¨ï¼Œå› æ­¤**å¤„ç†é€Ÿåº¦è¾ƒæ…¢ï¼Œæˆæœ¬ä¹Ÿæ›´é«˜**ã€‚

```python
from llama_index.node_parser.topic import TopicNodeParser

topic_node_parser = TopicNodeParser.from_defaults(similarity_method="llm")
nodes = topic_node_parser.get_nodes_from_documents(documents, show_progress=True)
```

# 5. åˆ›å»ºç´¢å¼• (Indexing)

ç´¢å¼•æ˜¯å°† `Node` å‘é‡åŒ–å¹¶å­˜å…¥å‘é‡æ•°æ®åº“çš„è¿‡ç¨‹ï¼Œä¸ºåç»­çš„å¿«é€Ÿæ£€ç´¢åšå‡†å¤‡ã€‚

## 5.1 æœ¬åœ°å­˜å‚¨

å¯¹äºå¼€å‘å’Œæµ‹è¯•é˜¶æ®µï¼Œå°†ç´¢å¼•å­˜å‚¨åœ¨æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿéå¸¸æ–¹ä¾¿ï¼Œä½†ä¸å»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨ã€‚

```python
from llama_index.core import VectorStoreIndex

index = VectorStoreIndex(nodes)
index.storage_context.persist(persist_dir="./dist/llama_index")
```

## 5.2 ä½¿ç”¨ PGVector æ•°æ®åº“

åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œæ¨èä½¿ç”¨ä¸“ä¸šçš„å‘é‡æ•°æ®åº“ï¼Œä¾‹å¦‚å¸¦æœ‰ `pg_vector` æ‰©å±•çš„ PostgreSQLã€‚

```python
from llama_index.core import VectorStoreIndex, StorageContext
from llama_index.vector_stores.postgres import PGVectorStore
import os
from sqlalchemy import make_url

connection_string = os.environ["DATABASE_URL"]
url = make_url(connection_string)

vector_store = PGVectorStore.from_params(
    database=url.database,
    host=url.host,
    password=url.password,
    port=str(url.port),
    user=url.username,
    table_name="knowledge",
    embed_dim=1536,  # å¿…é¡»ä¸ Embedding æ¨¡å‹çš„ç»´åº¦ä¸€è‡´
    hnsw_kwargs={
        "hnsw_m": 16,
        "hnsw_ef_construction": 64,
        "hnsw_ef_search": 40,
        "hnsw_dist_method": "vector_cosine_ops",
    },
)

storage_context = StorageContext.from_defaults(vector_store=vector_store)
index = VectorStoreIndex.from_documents(
    documents, storage_context=storage_context, show_progress=True
)
```

# 6. æŸ¥è¯¢ (Querying)

åˆ›å»ºç´¢å¼•åï¼Œå³å¯æ‰§è¡ŒæŸ¥è¯¢ã€‚é€šå¸¸æœ‰ä¸¤ç§æ¨¡å¼ï¼š

1.  **Retrieve + LLM**ï¼šå°†ç”¨æˆ·æŸ¥è¯¢å‘é‡åŒ–ï¼Œåœ¨å‘é‡æ•°æ®åº“ä¸­æ£€ç´¢æœ€ç›¸ä¼¼çš„ `Node`ï¼Œå°†è¿™äº› `Node` ä½œä¸ºä¸Šä¸‹æ–‡ä¿¡æ¯æä¾›ç»™ LLMï¼Œæœ€ç»ˆç”± LLM ç”Ÿæˆç­”æ¡ˆã€‚
2.  **Retrieve Only**ï¼šä»…ä»å‘é‡æ•°æ®åº“ä¸­æ£€ç´¢å¹¶è¿”å›ä¸æŸ¥è¯¢ç›¸ä¼¼çš„ `Node`ï¼Œä¸ç»è¿‡ LLM å¤„ç†ã€‚

## 6.1 åŸºäºæœ¬åœ°ç´¢å¼•æŸ¥è¯¢

```python
from llama_index.core import StorageContext, load_index_from_storage, QueryBundle
from llama_index.core.response.notebook_utils import display_source_node
from IPython.display import Markdown, display

# ä»æœ¬åœ°åŠ è½½ç´¢å¼•
storage_context = StorageContext.from_defaults(persist_dir="./dist/llama_index")
index = load_index_from_storage(storage_context)

# åˆ›å»ºæŸ¥è¯¢å¼•æ“
query_engine = index.as_query_engine(similarity_top_k=3)

question = QueryBundle("ä»€ä¹ˆæ˜¯å…‰åœºç”µæ°”æ¨¡å—ä¸­çš„ç»„ä»¶æ™ºèƒ½æ’å¸ƒåŠŸèƒ½?")
response = query_engine.query(question)

print("=" * 20 + "Answer" + "=" * 20)
display(Markdown(response.response))

# åˆ›å»ºæ£€ç´¢å™¨ï¼Œä»…æ£€ç´¢ä¸ç”Ÿæˆ
retriever = index.as_retriever(similarity_top_k=10)
retrieved_nodes = retriever.retrieve(question)

for i, node in enumerate(retrieved_nodes):
    print("=" * 20 + f"Retrived Node({i + 1})" + "=" * 20)
    display_source_node(node, source_length=10000)
```

## 6.2 åŸºäº PGVector ç´¢å¼•æŸ¥è¯¢

```python
from llama_index.core import VectorStoreIndex
from llama_index.vector_stores.postgres import PGVectorStore
import os
from sqlalchemy import make_url
from IPython.display import Markdown, display

connection_string = os.environ["DATABASE_URL"]
url = make_url(connection_string)

vector_store = PGVectorStore.from_params(
    database=url.database,
    host=url.host,
    password=url.password,
    port=str(url.port),
    user=url.username,
    table_name="knowledge",
    embed_dim=1536,
)

# ä»å‘é‡æ•°æ®åº“åŠ è½½ç´¢å¼•
index = VectorStoreIndex.from_vector_store(vector_store=vector_store)
query_engine = index.as_query_engine(similarity_top_k=3)

question = "SolarSketchå¹³å°çš„é˜´å½±å®æ—¶åˆ†æåŠŸèƒ½å¦‚ä½•å®ç°8760å°æ—¶é€æ—¶é˜´å½±æ¨¡æ‹Ÿ"
response = query_engine.query(question)

print("=" * 20 + "Answer:" + "=" * 20)
display(Markdown(response.response))  # type: ignore

# ä»…æ£€ç´¢
retriever = index.as_retriever(similarity_top_k=3)
retrieved_nodes = retriever.retrieve(question)

for i, node in enumerate(retrieved_nodes):
    print(print("=" * 20 + f"Retrived Knowledge({i + 1})" + "=" * 20))
    print(f"Score: {node.score:.4f}")
    print(f"Text: {node.get_content()}")
```

# 7. é«˜çº§æŠ€å·§: Rerank

åœ¨ RAG æµç¨‹ä¸­ï¼Œåˆæ­¥æ£€ç´¢ï¼ˆRetrieveï¼‰æ˜¯åŸºäºå‘é‡ç›¸ä¼¼åº¦è¿›è¡Œçš„ï¼Œå¾—åˆ†é«˜çš„ `Node` ä¸ä¸€å®šåŒ…å«æœ€å‡†ç¡®çš„ç­”æ¡ˆã€‚æ­¤æ—¶ï¼Œ**Rerankï¼ˆé‡æ’åºï¼‰** å°±å¯ä»¥å‘æŒ¥ä½œç”¨ã€‚å®ƒåˆ©ç”¨ä¸€ä¸ªæ›´ç²¾ç»†çš„æ¨¡å‹ï¼ˆé€šå¸¸æ˜¯ LLMï¼‰å¯¹åˆæ­¥æ£€ç´¢åˆ°çš„ `Node` åˆ—è¡¨è¿›è¡Œé‡æ–°æ’åºï¼Œå°†æœ€ç›¸å…³çš„å†…å®¹æ’åœ¨å‰é¢ï¼Œä»è€Œæå‡æœ€ç»ˆç”Ÿæˆç­”æ¡ˆçš„è´¨é‡ã€‚

```python
from llama_index.core.postprocessor.llm_rerank import LLMRerank
from llama_index.core import QueryBundle
from llama_index.core.response.notebook_utils import display_source_node

question = QueryBundle("ä»€ä¹ˆæ˜¯å…‰åœºç”µæ°”æ¨¡å—ä¸­çš„ç»„ä»¶æ™ºèƒ½æ’å¸ƒåŠŸèƒ½?")

# 1. åˆæ­¥æ£€ç´¢
retriever = index.as_retriever(similarity_top_k=10)
retrieved_nodes = retriever.retrieve(question)

# 2. ä½¿ç”¨ LLM Reranker å¯¹ç»“æœè¿›è¡Œé‡æ’åº
ranker = LLMRerank(top_n=5) # å‡è®¾æˆ‘ä»¬æœ€ç»ˆåªéœ€è¦æœ€ç›¸å…³çš„5ä¸ª
ranked_nodes = ranker.postprocess_nodes(retrieved_nodes, question)

# æ‰“å°é‡æ’åºå‰çš„èŠ‚ç‚¹
print("--- Retrieved Nodes (Before Rerank) ---")
for i, node in enumerate(retrieved_nodes):
    print("=" * 20 + f"Retrived Node({i + 1}) | Score: {node.score:.4f}" + "=" * 20)
    display_source_node(node, source_length=1000)

# æ‰“å°é‡æ’åºåçš„èŠ‚ç‚¹
print("\n--- Ranked Nodes (After Rerank) ---")
for i, node in enumerate(ranked_nodes):
    print("=" * 20 + f"Ranked Node({i + 1}) | Score: {node.score:.4f}" + "=" * 20)
    display_source_node(node, source_length=1000)
```

å°†é‡æ’åºåçš„ `ranked_nodes` ä½œä¸ºä¸Šä¸‹æ–‡æä¾›ç»™ LLMï¼Œå¯ä»¥æ˜¾è‘—æé«˜å›ç­”çš„å‡†ç¡®æ€§ã€‚

# 8. æ€»ç»“

æœ¬æ–‡è¯¦ç»†ä»‹ç»äº†ä½¿ç”¨ LlamaIndex æ¡†æ¶æ„å»ºä¸€ä¸ªå®Œæ•´ RAG åº”ç”¨çš„æ ¸å¿ƒæ­¥éª¤ã€‚æˆ‘ä»¬ä»ç¯å¢ƒé…ç½®å¼€å§‹ï¼Œä¾æ¬¡ç»å†äº†**åŠ è½½æ–‡æ¡£ã€æ‹†åˆ†æ–‡æ¡£ã€åˆ›å»ºç´¢å¼•ã€æ‰§è¡ŒæŸ¥è¯¢**ï¼Œå¹¶ä»‹ç»äº†ä½¿ç”¨ **Rerank** ä¼˜åŒ–æ£€ç´¢ç»“æœçš„é«˜çº§æŠ€å·§ã€‚

**æ ¸å¿ƒè¦ç‚¹å›é¡¾**:

- **é…ç½®å…ˆè¡Œ**: LlamaIndex çš„å…¨å±€ `Settings` æå¤§åœ°æ–¹ä¾¿äº†æ¨¡å‹çš„ç®¡ç†å’Œåˆ‡æ¢ã€‚
- **æ‹†åˆ†æ˜¯å…³é”®**: `Node` æ˜¯ RAG çš„åŸºçŸ³ï¼Œé€‰æ‹©åˆé€‚çš„æ‹†åˆ†ç­–ç•¥ï¼ˆå¦‚è¯­ä¹‰æ‹†åˆ†ï¼‰å¯¹æœ€ç»ˆæ•ˆæœæœ‰é‡è¦å½±å“ã€‚
- **ç´¢å¼•å­˜å‚¨**: æ ¹æ®åœºæ™¯é€‰æ‹©åˆé€‚çš„å­˜å‚¨æ–¹å¼ï¼Œå¼€å‘æ—¶ä½¿ç”¨æœ¬åœ°å­˜å‚¨ï¼Œç”Ÿäº§ç¯å¢ƒæ¨èä½¿ç”¨ PGVector ç­‰ä¸“ä¸šå‘é‡æ•°æ®åº“ã€‚
- **æŸ¥è¯¢ä¸ä¼˜åŒ–**: æ ‡å‡†çš„æŸ¥è¯¢å¼•æ“å¯ä»¥æ»¡è¶³å¤§éƒ¨åˆ†éœ€æ±‚ï¼Œè€Œå¼•å…¥ Rerank å¯ä»¥åœ¨æ­¤åŸºç¡€ä¸Šè¿›ä¸€æ­¥æå‡æ£€ç´¢ç»“æœçš„ç²¾å‡†åº¦ï¼Œæ˜¯ RAG åº”ç”¨ä¼˜åŒ–çš„é‡è¦ä¸€ç¯ã€‚

é€šè¿‡éµå¾ªè¿™äº›æ­¥éª¤ï¼Œæ‚¨å¯ä»¥å¿«é€Ÿåœ°åˆ©ç”¨ LlamaIndex å’Œé˜¿é‡Œäº‘ç™¾ç‚¼ç­‰æœåŠ¡ï¼Œæ„å»ºå‡ºåŠŸèƒ½å¼ºå¤§ä¸”é«˜æ•ˆçš„ RAG åº”ç”¨ã€‚
